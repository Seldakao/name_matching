{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from  scipy.sparse import find\n",
    "\n",
    "\n",
    "def remove_punctuations(X):\n",
    "    translator = X.maketrans('', '', string.punctuation)\n",
    "    return X.translate(translator)\n",
    "\n",
    "# remove lowercase for comparing initials, remove space directly\n",
    "def remove_lowercase(X):\n",
    "    translator = X.maketrans('', '', string.ascii_lowercase)\n",
    "    return X.translate(translator).replace(' ','')\n",
    "\n",
    "def remove_whitespace(X):\n",
    "    # remove the space and make lowercase here\n",
    "    return X.replace(' ', '')\n",
    "\n",
    "def make_lower(X):\n",
    "    # convert to lower case\n",
    "    return X.lower()\n",
    "\n",
    "def matching(Sample_slice,tf_idf_G, G_index, threshold):\n",
    "    '''\n",
    "      Matching procedure by using cosine similarity\n",
    "      Inputs:\n",
    "            Sample_slice: one row from the sparse matrix of Test table\n",
    "            tf_idf_G: tf-idf of Ground Truth (sparse)\n",
    "            G_index: column company_id from G '''\n",
    "    # Get the index of non-zero element in Sample_slice (the ngrams that are present in this document)    \n",
    "    # # v contains the nonzero columns    \n",
    "    i,v, j =find(Sample_slice)\n",
    "    # find the row index of ground truth that are not zeros (those groud truth documents that contain some of ngrams of test document)\n",
    "    x,y,z = find(tf_idf_G[:,v])\n",
    "    # take of slice of G (reduce the search space)\n",
    "    sub_G = tf_idf_G[:,v]\n",
    "    slice_G = sub_G[x,:]\n",
    "    # compute similarity\n",
    "    similarity_score = cosine_similarity(slice_G, Sample_slice[:,v], dense_output=True)\n",
    "    # index of highest similarity\n",
    "    max_index= similarity_score.argmax()\n",
    "    if similarity_score[max_index] >= threshold:\n",
    "        return G_index[x[max_index]]\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_matching(path_G,path_Test):\n",
    "    '''\n",
    "        Inputs:\n",
    "                path_G: path for Ground Truth csv in string format\n",
    "                path_Test: path for Test csv in string format\n",
    "    '''\n",
    "    \n",
    "    #Get the file name\n",
    "    G_file = path_G.split('/')[-1] # the last term is the file name\n",
    "    Test_file = path_Test\n",
    "    \n",
    "    Test = pd.read_csv(path_Test, sep = '|')\n",
    "    G = pd.read_csv(path_G, sep = '|')\n",
    "    # Make sure the index starts with 0 \n",
    "    G.reset_index(drop = True)\n",
    "    print('Files loaded')\n",
    "    \n",
    "    # remove all the punctuations\n",
    "    G['name_no_punc'] = G['name'].apply(remove_punctuations)\n",
    "    # after removing the punctuations, creating another one with only capital letters\n",
    "    #G['name_capital'] =G['name_no_punc'].apply(remove_lowercase)\n",
    "    G['name_no_punc'] = G['name_no_punc'].apply(make_lower)\n",
    "    #G['name_no_punc_no_space'] = G['name_no_punc'].apply(remove_whitespace)\n",
    "\n",
    "    # Same transformation for STrain\n",
    "    Test['name_no_punc'] = Test['name'].apply(remove_punctuations)\n",
    "    #Test['name_capital'] =Test['name_no_punc'].apply(remove_lowercase)\n",
    "    Test['name_no_punc'] = Test['name_no_punc'].apply(make_lower)\n",
    "    #Test['name_no_punc_no_space'] = Test['name_no_punc'].apply(remove_whitespace)\n",
    "    print('Text Preprocessing completed')\n",
    "    \n",
    "    # Perpare answer sheet\n",
    "    Matching_table = pd.DataFrame([],index = Test.index, columns=['company_id'])\n",
    "    # Company_id from Ground Truth\n",
    "    Company_id = G['company_id']\n",
    "    # tfidf ground truth\n",
    "    tfidf = TfidfVectorizer(min_df=1, analyzer='char', ngram_range = (3,3))\n",
    "    tf_idf_G = tfidf.fit_transform(G['name_no_punc'])\n",
    "    # transform Test\n",
    "    tf_idf_Test = tfidf.transform(Test['name_no_punc'])\n",
    "    print('tf-idf transformation completed')\n",
    "    \n",
    "    # predict one company at a time\n",
    "    t = time.time()\n",
    "    print('Matching process begins..')\n",
    "    predict_index = []\n",
    "    for i in range(Test.shape[0]):\n",
    "        pred = matching(tf_idf_Test[i,:],tf_idf_G,Company_id, 0.89)\n",
    "        predict_index.append(pred)\n",
    "        \n",
    "    timespent = time.time() - t\n",
    "    print('Matching process ended, running time is {} seconds'.format(timespent)) \n",
    "    \n",
    "    # produce answer sheet\n",
    "    Matching_table['company_id'] = predict_index\n",
    "    Matching_table.to_csv('Matching_table.csv', sep='|', encoding='utf-8',index = True, index_label = 'test_index')\n",
    "    print('Matching_table.csv is saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.read_csv('STest.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample = Test.sample(n=100)\n",
    "Sample.to_csv('Sample_test.csv', sep='|', encoding='utf-8',index = True, index_label ='test_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded\n",
      "Text Preprocessing completed\n",
      "tf-idf transformation completed\n",
      "Matching process begins..\n",
      "Matching process ended, running time is 16.626711130142212 seconds\n",
      "Matching_table.csv is saved.\n"
     ]
    }
   ],
   "source": [
    "name_matching('G.csv','Sample_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WBAA_task import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded\n",
      "Text Preprocessing completed\n",
      "tf-idf transformation completed\n",
      "Matching process begins..\n",
      "Matching process ended, running time is 16.858201026916504 seconds\n",
      "Matching_table.csv is saved.\n"
     ]
    }
   ],
   "source": [
    "name_matching('G.csv','Sample_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
